{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Performance Improvement in Deep Learning Architecture for Phonocardiogram Signal Classification using Spectrogram","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:52:18.340609Z","iopub.execute_input":"2022-02-03T04:52:18.341291Z","iopub.status.idle":"2022-02-03T04:52:18.346826Z","shell.execute_reply.started":"2022-02-03T04:52:18.341253Z","shell.execute_reply":"2022-02-03T04:52:18.346048Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Remove the folder recursively:\n#shutil.rmtree('/kaggle/working/image_data/abnormal')\n#shutil.rmtree('/kaggle/working/image_data/normal')\n#shutil.rmtree('/kaggle/working/image_data')\n\n# Create the directory for image data\nos.mkdir('/kaggle/working/image_data/')\nos.mkdir('/kaggle/working/image_data/abnormal')\nos.mkdir('/kaggle/working/image_data/normal')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T04:52:18.351258Z","iopub.execute_input":"2022-02-03T04:52:18.351479Z","iopub.status.idle":"2022-02-03T04:52:18.358849Z","shell.execute_reply.started":"2022-02-03T04:52:18.351453Z","shell.execute_reply":"2022-02-03T04:52:18.358154Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Imports used\nimport numpy as np\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport wave\nimport pylab\nfrom pathlib import Path\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport gc\n\n\nplt.style.use('dark_background')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:52:18.363732Z","iopub.execute_input":"2022-02-03T04:52:18.363927Z","iopub.status.idle":"2022-02-03T04:52:18.369593Z","shell.execute_reply.started":"2022-02-03T04:52:18.363903Z","shell.execute_reply":"2022-02-03T04:52:18.368830Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Loading the signals from the .wav format","metadata":{}},{"cell_type":"code","source":"#Input directory where the wav files are stored\ninput_directory = '../input/spectogram/data'\n\nwav_temp = os.listdir(input_directory)\nwav = []\n\nfor i in range(len(wav_temp)) :\n    if(wav_temp[i].endswith(\".wav\")):\n        wav.append(wav_temp[i])\n\nwav.sort()\nfor i in range(10):\n    \n    if(wav[i].endswith(\".wav\")):\n        file_name = wav[i][0:5]\n        \n        if(file_name[0] == 'e'):\n              file_name = wav[i][0:6]\n        \n        with open(input_directory+'/'+file_name+'.hea') as f:\n            lines = f.read().splitlines()\n            last_line = lines[-1].split()[1]\n            print(file_name + \" \" + last_line)\n\ngc.collect()\ndel wav_temp","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:52:18.383788Z","iopub.execute_input":"2022-02-03T04:52:18.383982Z","iopub.status.idle":"2022-02-03T04:52:18.589608Z","shell.execute_reply.started":"2022-02-03T04:52:18.383958Z","shell.execute_reply":"2022-02-03T04:52:18.588795Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Reading the signals and normalizing them","metadata":{}},{"cell_type":"code","source":"#Opening the wav file \nsignal_wave = wave.open(os.path.join(input_directory, wav[6]), 'r')\n\n#Specifying sample_rate\nsample_rate = 50000\nsig = np.frombuffer(signal_wave.readframes(sample_rate), dtype=np.int16)\n\nmax_data = np.max(sig)\nmin_data = np.min(sig)\nnorm_signal = (sig - min_data)/(max_data - min_data)\nsig = norm_signal - 0.5\n\n#Creating the figure\nplt.figure(figsize=(12,12))\nsig_plot = plt.subplot(211)\nsig_plot.set_title(wav[6])\nsig_plot.plot(sig)\nsig_plot.set_xlabel('Sample Rate * Time')\nsig_plot.set_ylabel('Energy')\n\nspectogram_plot = plt.subplot(212)\nspectogram_plot.specgram(sig, NFFT=1024, Fs=sample_rate, noverlap=900)\nspectogram_plot.set_xlabel('Time')\nspectogram_plot.set_ylabel('Frequency')\n\nplt.show()\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:52:18.590887Z","iopub.execute_input":"2022-02-03T04:52:18.591079Z","iopub.status.idle":"2022-02-03T04:52:19.219598Z","shell.execute_reply.started":"2022-02-03T04:52:18.591055Z","shell.execute_reply":"2022-02-03T04:52:19.218929Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Step 1 : Read all the .wav files and convert to spectogram and save as png in respective class folders","metadata":{}},{"cell_type":"code","source":"#To limit the signal to 5 seconds\ndef Limit(S,Fs):\n    if(len(S)/Fs>=5):\n        S=S[:5*Fs]\n    else:\n        for i in range(len(S),5*Fs):\n            S=np.append(S,0)\n    return S\n\n#Function to get sound and frame info\ndef get_wav_info(wav_file):\n    wav = wave.open(wav_file, 'r')\n    frames = wav.readframes(-1)\n    sound_info = pylab.frombuffer(frames, 'int16')\n    frame_rate = wav.getframerate()\n    wav.close()\n    return sound_info, frame_rate\n\n#Function to get the class label\ndef get_class(hea_file):\n    \n    #Reading the corresponding header file\n    with open(input_directory+'/'+hea_file+'.hea') as f:\n            lines = f.read().splitlines()\n            last_line = lines[-1].split()[1]\n            \n    return last_line\n\n#Output directory where the images of spectogram are stored\noutput_directory = './image_data/'\n\nfor filename in wav:\n    \n    #Making sure only wav files are read\n    if \"wav\" in filename:\n        \n        file_path = os.path.join(input_directory, filename)\n        file_stem = Path(file_path).stem\n        \n        #Getting the target directory\n        target_dir = f'{get_class(file_stem)}'\n        \n        dist_dir = output_directory+target_dir.lower()\n        \n        file_dist_path = os.path.join(dist_dir, file_stem)\n        \n        #Converting signal to spectogram and saving as png\n        if not os.path.exists(file_dist_path + '.png'):\n            file_stem = Path(file_path).stem\n            sound_info, frame_rate = get_wav_info(file_path)\n            sig = Limit(sound_info,frame_rate)\n            max_data = np.max(sig)\n            min_data = np.min(sig)\n            norm_signal = (sig - min_data)/(max_data - min_data)\n            sig = norm_signal - 0.5\n            pylab.specgram(sig, Fs=frame_rate)\n            pylab.savefig(f'{file_dist_path}.png')\n            pylab.close()\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:52:19.220903Z","iopub.execute_input":"2022-02-03T04:52:19.221362Z","iopub.status.idle":"2022-02-03T04:53:07.835172Z","shell.execute_reply.started":"2022-02-03T04:52:19.221327Z","shell.execute_reply":"2022-02-03T04:53:07.833939Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Step 2 : Read all images and convert them to numpy arrays and also the class labels\n\n#### 1. Read the image\n#### 2. Resize image to 128 x 128 x 3 \n#### 3. Normalize image by taking max and min values for each image\n#### 4. Oversample the respective class if needed (If no augmentation, 3rd input must be greater than number of classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:08:02.885167Z","iopub.execute_input":"2021-12-02T13:08:02.885906Z","iopub.status.idle":"2021-12-02T13:08:02.891392Z","shell.execute_reply.started":"2021-12-02T13:08:02.885867Z","shell.execute_reply":"2021-12-02T13:08:02.890526Z"}}},{"cell_type":"code","source":"#To read the images into an array\nfrom tqdm import tqdm\nimport cv2\n\n#Properties of image\nIMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128\nN_CHANNELS = 3\n\n#Number of classes\nN_CLASSES = 2\n\nfrom skimage import transform\nfrom tensorflow.keras import layers\n\ndef load_data(data,num_classes,class_label,augmen_times):\n    \n    X = []\n    y = []\n    \n    #To traverse every spectogram image in data \n    for file_type in os.listdir(data):\n        \n        if not file_type.startswith('.'):\n            \n        #It is binary classification so we have two class labels 0 and 1 \n        #If ABNORMAL the label will be 1\n        #If NORMAL the label will be 0\n            if file_type in ['abnormal']:\n                label = 1\n            elif file_type in ['normal']:\n                label = 0\n            \n            for filename in tqdm(os.listdir(data + '/' + file_type)):\n                #To read every image from the folders\n                image = cv2.imread(data +'/'+ file_type + '/' + filename)\n                \n                #If the image is found\n                if image is not None:\n                    \n                    #To resize the random sized images into a fixed size of 128x128x3\n                    image = transform.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS))\n                    \n                    #Changing the datatype into array to process through the cnn algorithm\n                    image_data_as_arr = np.asarray(image)\n                    \n                    del image\n                    \n                    #Augmented addition abnormal images if detected\n                    if(label==class_label and class_label<num_classes):\n                        data_augmentation = tf.keras.Sequential([\n                                             layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n                                            layers.experimental.preprocessing.RandomRotation(0.2)])\n                        for i in range(augmen_times):\n                            augmented_image = data_augmentation(image_data_as_arr)\n                            X.append(augmented_image)\n                            y.append(label)\n                            \n                    #Appending the data in the empty lists of X and y\n                    X.append(image_data_as_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    \n    return X,y\n\n\n#Loading the train data\nX_train, y_train = load_data(r'./image_data/',2,1,3)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.836365Z","iopub.status.idle":"2022-02-03T04:53:07.837044Z","shell.execute_reply.started":"2022-02-03T04:53:07.836803Z","shell.execute_reply":"2022-02-03T04:53:07.836831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Printing count of each class to make sure there is no imbalance in dataset","metadata":{}},{"cell_type":"code","source":"#Getting counts of each labels\nunique, counts = np.unique(y_train, return_counts=True)\ndict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.838027Z","iopub.status.idle":"2022-02-03T04:53:07.838799Z","shell.execute_reply.started":"2022-02-03T04:53:07.838545Z","shell.execute_reply":"2022-02-03T04:53:07.838571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n#Plotting all the spectogram images\nplt.figure(figsize=(12, 12))\n\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    rand_num = random.randint(0,len(X_train))\n    plt.imshow(X_train[rand_num])\n    plt.title(int(y_train[rand_num]))\n    plt.axis(\"off\")\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.839819Z","iopub.status.idle":"2022-02-03T04:53:07.840123Z","shell.execute_reply.started":"2022-02-03T04:53:07.839957Z","shell.execute_reply":"2022-02-03T04:53:07.839976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3 : Split the dataset into train and test and perform one hot encoding on class labels","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\n#Splitting the train and test data\nxTrain, xTest, yTrain, yTest = train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n\n#One hot encoding the labels\ny_trainHot = np.uint8(to_categorical(yTrain, num_classes = 2))\ny_testHot = np.uint8(to_categorical(yTest, num_classes = 2))\n\ngc.collect()\n\n#del X_train\n#del y_train","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.842031Z","iopub.status.idle":"2022-02-03T04:53:07.842706Z","shell.execute_reply.started":"2022-02-03T04:53:07.842467Z","shell.execute_reply":"2022-02-03T04:53:07.842502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4 : Make the CNN model and train the model with the respective parameters","metadata":{"execution":{"iopub.status.busy":"2021-12-01T18:50:24.070003Z","iopub.execute_input":"2021-12-01T18:50:24.070696Z","iopub.status.idle":"2021-12-01T18:51:30.556944Z","shell.execute_reply.started":"2021-12-01T18:50:24.070655Z","shell.execute_reply":"2021-12-01T18:51:30.556147Z"}}},{"cell_type":"code","source":"#The main CNN architecture\nimport keras\nfrom keras import models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, MaxPool2D\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n#The binary labels for our CNN model in the form of a dictionary\nbin_labels = {0:'Normal',1:'Abnormal'}\n\ndef CNN(imgs,img_labels,test_imgs,test_labels,stride):\n    \n    #Number of classes (2)\n    num_classes = len(img_labels[0])\n    \n    epochs = 30\n    \n    #Size of image\n    img_rows,img_cols=imgs.shape[1],imgs.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    \n    #Creating the model\n    model = Sequential()\n    \n    #First convolution layer\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape,\n                     strides=stride))\n    \n    #First maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Dropout(0.2))\n    \n    #Second convolution layer\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    \n    #Second maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    #Third convolution layer\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    \n    #Third maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Dropout(0.2))\n    \n    #Convert the matrix to a fully connected layer\n    model.add(Flatten())\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    model.add(Dropout(0.2))\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    #Final dense layer on which softmax function is performed\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    #Model parameters\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adamax',\n                  metrics=['binary_accuracy'])\n    \n    #Evaluate the model on the test data before training your model\n    score = model.evaluate(test_imgs,test_labels, verbose=1)\n    \n    print('\\nKeras CNN binary accuracy:', score[1],'\\n')\n    \n    #The model details\n    history = model.fit(imgs,img_labels,\n                        shuffle = True, \n                        epochs=epochs, \n                        validation_data = (test_imgs, test_labels))\n    \n    #Evaluate the model on the test data after training your model\n    score = model.evaluate(test_imgs,test_labels, verbose=1)\n    print('\\nKeras CNN binary accuracy:', score[1],'\\n')\n    \n    #Predict the labels from test data\n    y_pred = model.predict(test_imgs)\n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    Y_true = np.argmax(test_labels,axis=1)\n    \n    #Correct labels\n    for i in range(len(Y_true)):\n        if(Y_pred_classes[i] == Y_true[i]):\n            print(\"The predicted class is : \" , Y_pred_classes[i])\n            print(\"The real class is : \" , Y_true[i])\n            break\n            \n    #The confusion matrix made from the real Y values and the predicted Y values\n    confusion_mtx = [Y_true, Y_pred_classes]\n    \n    #Summary of the model\n    model.summary()\n    \n    return model,confusion_mtx\n   \nmodel,conf_mat = CNN(xTrain,y_trainHot,xTest,y_testHot,1);","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.843935Z","iopub.status.idle":"2022-02-03T04:53:07.844574Z","shell.execute_reply.started":"2022-02-03T04:53:07.844338Z","shell.execute_reply":"2022-02-03T04:53:07.844362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n\n#Predict the labels from test data\ny_pred = model.predict(xTest)\nY_pred_classes = np.argmax(y_pred,axis=1) \nY_true = np.argmax(y_testHot,axis=1)\n\nfrom sklearn.metrics import precision_recall_fscore_support\nprec,recall,f1,_ = precision_recall_fscore_support(Y_true,Y_pred_classes,average='binary')\n\nprint(\"Precision : \", prec)\nprint(\"Recall : \", recall)\nprint(\"F1 score : \", f1)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:53:07.845754Z","iopub.status.idle":"2022-02-03T04:53:07.846391Z","shell.execute_reply.started":"2022-02-03T04:53:07.846145Z","shell.execute_reply":"2022-02-03T04:53:07.846169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}